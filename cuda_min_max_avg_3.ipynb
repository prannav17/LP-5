{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "RUHAAN HAWALDAR BE 21137"
      ],
      "metadata": {
        "id": "lDHyP260xdGC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n"
      ],
      "metadata": {
        "id": "X8lMKo22kJEA"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHOUTKoSkMqJ",
        "outputId": "03e3128c-345b-42f1-9037-3af5b62090f6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile max_cuda.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <cuda.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "__global__ void max1(int* input, int size) {\n",
        "    int tid = threadIdx.x;\n",
        "\n",
        "    for (int step_size = 1; step_size < size; step_size *= 2) {\n",
        "        if (tid % (2 * step_size) == 0) {\n",
        "            int first = tid;\n",
        "            int second = tid + step_size;\n",
        "\n",
        "            if (second < size) {\n",
        "                if (input[first] < input[second]) {\n",
        "                    input[first] = input[second];\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    const int count = 8;\n",
        "    const int size = count * sizeof(int);\n",
        "    int h[count] = {13, 65, 15, 14, 33, 2, 30, 8};\n",
        "\n",
        "    int* d;\n",
        "    cudaMalloc(&d, size);\n",
        "    cudaMemcpy(d, h, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    max1<<<1, count / 2>>>(d, count);\n",
        "\n",
        "    int result;\n",
        "    cudaMemcpy(&result, d, sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    printf(\"Largest number is: %d\\n\", result);\n",
        "\n",
        "    cudaFree(d);\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8s9We51kOgD",
        "outputId": "4f11919e-c38b-4aeb-db31-e4a9e7e6ca06"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing max_cuda.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc max_cuda.cu -o max_cuda"
      ],
      "metadata": {
        "id": "K8larT6BkUBA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./max_cuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jghZ_dxqkWzV",
        "outputId": "3a4581c4-036c-4915-e6ea-f56a5c8518b4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Largest number is: 13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile min_cuda.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <cuda.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "__global__ void min1(int* input) {\n",
        "    int tid = threadIdx.x;\n",
        "    int step_size = 1;\n",
        "    int number_of_threads = blockDim.x;\n",
        "    int temp;\n",
        "\n",
        "    while (number_of_threads > 0) {\n",
        "        if (tid < number_of_threads) {\n",
        "            int fst = tid * step_size * 2;\n",
        "            int snd = fst + step_size;\n",
        "\n",
        "            if (input[fst] > input[snd]) {\n",
        "                temp = input[fst];\n",
        "                input[fst] = input[snd];\n",
        "                input[snd] = temp;\n",
        "            }\n",
        "        }\n",
        "        __syncthreads();\n",
        "        step_size <<= 1;\n",
        "        number_of_threads >>= 1;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    const int count = 8;\n",
        "    const int size = count * sizeof(int);\n",
        "    int h[] = {13, 65, 15, 14, 33, 23, 30, 8};\n",
        "\n",
        "    int* d;\n",
        "    cudaMalloc(&d, size);\n",
        "    cudaMemcpy(d, h, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    min1<<<1, count / 2>>>(d);\n",
        "\n",
        "    int result;\n",
        "    cudaMemcpy(&result, d, sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    printf(\"Smallest number is: %d\\n\", result);\n",
        "\n",
        "    cudaFree(d);\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jp2ybP2AkdCi",
        "outputId": "5f903659-2cfd-4d03-b2e0-4ba9e4983aa4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing min_cuda.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc min_cuda.cu -o min_cuda\n",
        "!./min_cuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_Dx210rkeOi",
        "outputId": "ed428c6a-4a95-4f5d-eec2-2b103715910b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Smallest number is: 13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile sum_avg_cuda.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <cuda.h>\n",
        "\n",
        "__global__ void sum(int* input) {\n",
        "    int tid = threadIdx.x;\n",
        "    int step_size = 1;\n",
        "    int number_of_threads = blockDim.x;\n",
        "\n",
        "    while (number_of_threads > 0) {\n",
        "        if (tid < number_of_threads) {\n",
        "            int fst = tid * step_size * 2;\n",
        "            int snd = fst + step_size;\n",
        "            input[fst] += input[snd];\n",
        "        }\n",
        "        __syncthreads();\n",
        "        step_size <<= 1;\n",
        "        number_of_threads >>= 1;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    const int count = 8; // Total elements\n",
        "    const int size = count * sizeof(int);\n",
        "    int h[] = {13, 27, 15, 14, 33, 2, 30, 8}; // Input array\n",
        "\n",
        "    int* d;\n",
        "    cudaMalloc(&d, size);\n",
        "    cudaMemcpy(d, h, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    sum<<<1, count / 2>>>(d); // Call kernel function\n",
        "\n",
        "    int result;\n",
        "    cudaMemcpy(&result, d, sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    float avg = (float)result / count; // Calculate average\n",
        "\n",
        "    printf(\"Sum is %d\\n\", result);\n",
        "    printf(\"Average is %.2f\\n\", avg);\n",
        "\n",
        "    cudaFree(d);\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjGUZGqAkjJP",
        "outputId": "d8c17c59-be1d-4502-c8b9-f1d09b1c3d22"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing sum_avg_cuda.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc sum_avg_cuda.cu -o sum_avg_cuda\n",
        "!./sum_avg_cuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VLEcea2kkVs",
        "outputId": "a0e7ead3-f94d-4e13-ca97-0b0257bc30cd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sum is 13\n",
            "Average is 1.62\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FIUItshHlaVs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}