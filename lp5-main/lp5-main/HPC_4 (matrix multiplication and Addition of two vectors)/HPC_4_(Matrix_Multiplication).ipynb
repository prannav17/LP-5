{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# (Important) first go to runtime -> change runtime type -> Select T4 - GPU (Any Available GPU) -> Save\n",
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Se_19DqN35CV",
        "outputId": "307b7dfa-2e6e-45c5-c747-0df70815eeb4"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Debug log: Check whether the Runtime is GPU based or not!\n",
        "import torch\n",
        "torch.cuda.is_available() # Should be True\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uN7Oems4PoS",
        "outputId": "1f5c9579-00f6-4dd3-e3b0-7e373190508d"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "K8TF2IBuxkcv"
      },
      "outputs": [],
      "source": [
        "cuda_code = r\"\"\"\n",
        "#include <cuda_runtime.h>\n",
        "#include <iostream>\n",
        "\n",
        "// Use long long int for calculations to prevent overflow\n",
        "__global__ void matmul(int* A, int* B, long long int* C, int N) {\n",
        "    int Row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int Col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (Row < N && Col < N) {\n",
        "        long long int Pvalue = 0;\n",
        "        for (int k = 0; k < N; k++) {\n",
        "            Pvalue += (long long int)A[Row * N + k] * B[k * N + Col];\n",
        "        }\n",
        "        C[Row * N + Col] = Pvalue;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    // Use a smaller matrix size for easier verification\n",
        "    int N = 8;\n",
        "    int size = N * N * sizeof(int);\n",
        "    size_t result_size = N * N * sizeof(long long int);\n",
        "\n",
        "    // Allocate CPU memory\n",
        "    int* A = (int*)malloc(size);\n",
        "    int* B = (int*)malloc(size);\n",
        "    long long int* C = (long long int*)malloc(result_size);\n",
        "\n",
        "    // Initialize matrices A and B with simple values\n",
        "    // Matrix A: simple incremental values\n",
        "    int A_data[64] = {\n",
        "        1, 2, 3, 4, 5, 6, 7, 8,\n",
        "        9, 10, 11, 12, 13, 14, 15, 16,\n",
        "        17, 18, 19, 20, 21, 22, 23, 24,\n",
        "        25, 26, 27, 28, 29, 30, 31, 32,\n",
        "        33, 34, 35, 36, 37, 38, 39, 40,\n",
        "        41, 42, 43, 44, 45, 46, 47, 48,\n",
        "        49, 50, 51, 52, 53, 54, 55, 56,\n",
        "        57, 58, 59, 60, 61, 62, 63, 64\n",
        "    };\n",
        "\n",
        "    // Matrix B: identity matrix for simplicity\n",
        "    int B_data[64] = {\n",
        "        1, 0, 0, 0, 0, 0, 0, 0,\n",
        "        0, 1, 0, 0, 0, 0, 0, 0,\n",
        "        0, 0, 1, 0, 0, 0, 0, 0,\n",
        "        0, 0, 0, 1, 0, 0, 0, 0,\n",
        "        0, 0, 0, 1, 1, 0, 0, 0,\n",
        "        0, 0, 0, 0, 0, 1, 0, 0,\n",
        "        0, 0, 0, 0, 0, 0, 1, 0,\n",
        "        0, 0, 0, 0, 0, 0, 0, 1\n",
        "    };\n",
        "\n",
        "    // Copy the data to A and B\n",
        "    memcpy(A, A_data, size);\n",
        "    memcpy(B, B_data, size);\n",
        "\n",
        "    // Print matrix A\n",
        "    std::cout << \"Matrix A:\" << std::endl;\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        for (int j = 0; j < N; j++) {\n",
        "            std::cout << A[i * N + j] << \" \";\n",
        "        }\n",
        "        std::cout << std::endl;\n",
        "    }\n",
        "\n",
        "    // Print matrix B\n",
        "    std::cout << \"\\nMatrix B:\" << std::endl;\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        for (int j = 0; j < N; j++) {\n",
        "            std::cout << B[i * N + j] << \" \";\n",
        "        }\n",
        "        std::cout << std::endl;\n",
        "    }\n",
        "\n",
        "    // Allocate GPU memory\n",
        "    int* dev_A, * dev_B;\n",
        "    long long int* dev_C;\n",
        "    cudaMalloc(&dev_A, size);\n",
        "    cudaMalloc(&dev_B, size);\n",
        "    cudaMalloc(&dev_C, result_size);\n",
        "\n",
        "    // Copy A and B to device memory\n",
        "    cudaMemcpy(dev_A, A, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(dev_B, B, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Define block and grid sizes\n",
        "    dim3 dimBlock(8, 8); // 8×8 threads per block for the 8×8 matrix\n",
        "    dim3 dimGrid(1, 1);  // Only need one block for 8×8 matrix\n",
        "\n",
        "    // Timing GPU kernel execution\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "    cudaEventRecord(start);\n",
        "\n",
        "    // Launch kernel\n",
        "    matmul<<<dimGrid, dimBlock>>>(dev_A, dev_B, dev_C, N);\n",
        "\n",
        "    // Check for kernel launch errors\n",
        "    cudaError_t err = cudaGetLastError();\n",
        "    if (err != cudaSuccess) {\n",
        "        std::cout << \"CUDA kernel launch error: \" << cudaGetErrorString(err) << std::endl;\n",
        "        cudaFree(dev_A);\n",
        "        cudaFree(dev_B);\n",
        "        cudaFree(dev_C);\n",
        "        free(A);\n",
        "        free(B);\n",
        "        free(C);\n",
        "        return -1;\n",
        "    }\n",
        "\n",
        "    // Add explicit synchronization\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);\n",
        "\n",
        "    float milliseconds = 0;\n",
        "    cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "\n",
        "    // Copy result back to CPU\n",
        "    cudaMemcpy(C, dev_C, result_size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Print the resulting matrix C\n",
        "    std::cout << \"\\nMatrix C (Result):\" << std::endl;\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        for (int j = 0; j < N; j++) {\n",
        "            std::cout << C[i * N + j] << \" \";\n",
        "        }\n",
        "        std::cout << std::endl;\n",
        "    }\n",
        "\n",
        "    // Print execution time\n",
        "    std::cout << \"\\nMatrix multiplication completed in \" << milliseconds << \" ms\\n\";\n",
        "\n",
        "    // Verify CPU calculation for comparison\n",
        "    std::cout << \"\\nCPU Verification:\" << std::endl;\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        for (int j = 0; j < N; j++) {\n",
        "            long long int value = 0;\n",
        "            for (int k = 0; k < N; k++) {\n",
        "                value += (long long int)A[i * N + k] * B[k * N + j];\n",
        "            }\n",
        "            std::cout << value << \" \";\n",
        "        }\n",
        "        std::cout << std::endl;\n",
        "    }\n",
        "\n",
        "    // Free memory\n",
        "    cudaFree(dev_A);\n",
        "    cudaFree(dev_B);\n",
        "    cudaFree(dev_C);\n",
        "    free(A);\n",
        "    free(B);\n",
        "    free(C);\n",
        "\n",
        "    return 0;\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "with open('mat_multi.cu', 'w') as f:\n",
        "    f.write(cuda_code)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc mat_multi.cu -o mat_multi -arch=sm_75 # -arch=sm_75 signifies For CUDA 12.5 with a T4 GPU (compute capability 7.5),"
      ],
      "metadata": {
        "id": "OwGzIEQqx0Bp"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./mat_multi\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AyuMZahx52P",
        "outputId": "b6fcfb2e-0d7f-422d-e522-07fbeed00a92"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix A:\n",
            "1 2 3 4 5 6 7 8 \n",
            "9 10 11 12 13 14 15 16 \n",
            "17 18 19 20 21 22 23 24 \n",
            "25 26 27 28 29 30 31 32 \n",
            "33 34 35 36 37 38 39 40 \n",
            "41 42 43 44 45 46 47 48 \n",
            "49 50 51 52 53 54 55 56 \n",
            "57 58 59 60 61 62 63 64 \n",
            "\n",
            "Matrix B:\n",
            "1 0 0 0 0 0 0 0 \n",
            "0 1 0 0 0 0 0 0 \n",
            "0 0 1 0 0 0 0 0 \n",
            "0 0 0 1 0 0 0 0 \n",
            "0 0 0 1 1 0 0 0 \n",
            "0 0 0 0 0 1 0 0 \n",
            "0 0 0 0 0 0 1 0 \n",
            "0 0 0 0 0 0 0 1 \n",
            "\n",
            "Matrix C (Result):\n",
            "1 2 3 9 5 6 7 8 \n",
            "9 10 11 25 13 14 15 16 \n",
            "17 18 19 41 21 22 23 24 \n",
            "25 26 27 57 29 30 31 32 \n",
            "33 34 35 73 37 38 39 40 \n",
            "41 42 43 89 45 46 47 48 \n",
            "49 50 51 105 53 54 55 56 \n",
            "57 58 59 121 61 62 63 64 \n",
            "\n",
            "Matrix multiplication completed in 0.106496 ms\n",
            "\n",
            "CPU Verification:\n",
            "1 2 3 9 5 6 7 8 \n",
            "9 10 11 25 13 14 15 16 \n",
            "17 18 19 41 21 22 23 24 \n",
            "25 26 27 57 29 30 31 32 \n",
            "33 34 35 73 37 38 39 40 \n",
            "41 42 43 89 45 46 47 48 \n",
            "49 50 51 105 53 54 55 56 \n",
            "57 58 59 121 61 62 63 64 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bVFW6Rmuy7OI"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tcrPVzzLzcmV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}